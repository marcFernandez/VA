{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision - Laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "## Practicum 3: Image and Video Segmentation\n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main topics are:\n",
    "\n",
    "1)\tSegmentation of video shots with static scenes.\n",
    "\n",
    "2) Background substraction.\n",
    "\n",
    "3)\tSegmentation of images.\n",
    "\n",
    "In order to successfuly complete this practicum it is necessary to understand the following theory concepts: background substraction, K-means clustering, etc.\n",
    "\n",
    "The following chapters of the book “Computer Vision: Algorithms and Applicatons” from Richard Szeliski have further information about the topic:\n",
    "\n",
    "* Chapter 4: Computer Vision: Algorithms and Applications.\n",
    "\n",
    "* Chapter 5: Segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Background substraction methods\n",
    "\n",
    "\n",
    "Given the video stored in ‘Barcelona-sequence’, which contains images acquired by a static camera, remove all the \"artifacts\" considered as foreground related to movement extracting the background images.\n",
    "\n",
    "Note: One of the applications of these methods is the button \"remove tourists\" implemented in most commercial photo cameras. For instance, Adobe uses the \"Monument Mode\", which automatically deletes the people going by the cameras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and visualize the sequence of images \"images/Barcelona-sequence\"\n",
    "Hint: In order to read a  collection of images, we wil use the function animation.FuncAnimation [https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.animation.FuncAnimation.html].\n",
    "\n",
    "Observe in the following example, how FuncAnimation is used to read and visualize a sequence of frames. Explore the parameters of animation.FuncAnimation()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ic = io.ImageCollection('images/Barcelona-sequence/*.png')\n",
    "        # Reading a sequence of images from a folder\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib nbagg \n",
    "    #Changing the pluggin is necessary always when visualizing a video!\n",
    "\n",
    "i=0       #Inicializing the video display\n",
    "fig = plt.figure()  # Create figure\n",
    "im = plt.imshow(ic[i], animated=True) #Visualize the first image\n",
    "\n",
    "def updatefig1(i):   #Updating the frame visualization\n",
    "    im.set_array(ic[i*5]) #Changing the content of the canvas\n",
    "    return im, #to return a tuple!\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig1, interval=5, blit=False, frames=50, repeat= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Find where a shot (scene) finishes and the following starts (boundaries). Each of the scenes in a video is usually called 'shot'. Which measure can be used in order to visually distinguish the shots in a plot? Explain your solution.\n",
    "\n",
    "Show the initial and final images of each shot extracted as follows:\n",
    "\n",
    "<img src=\"images_for_notebook/result_shot_detection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** take the following example of video and temporal plot visualization as a template. The plot must be replaced by a frame by frame measure to be defined by you, being applicable to distinguish the shots.\n",
    "\n",
    "- If you need to convert the image to float, the command is: img_as_float()\n",
    "- If you need the histogram, it is in skimage.exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ic_gray = [skimage.color.rgb2gray(frame) for frame in ic]\n",
    "\n",
    "histoarray = [np.histogram(frame) for frame in ic_gray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "\n",
    "for i in range(len(histoarray)):\n",
    "    curr = histoarray[i]\n",
    "    means.append(np.mean(curr[0]))\n",
    "    stds.append(np.std(curr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosas = []\n",
    "\n",
    "# We add to our histogram array the values letting them between 0 and 1\n",
    "for i in range(len(histoarray)):\n",
    "    y = means[i] + stds[i]\n",
    "    cosas.append(y/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Sinusoidal plot points generation\n",
    "def data_gen():\n",
    "    t = data_gen.t\n",
    "    cnt = 0\n",
    "    \n",
    "    while cnt < len(ic):\n",
    "        cnt+=1\n",
    "        t += 0.05\n",
    "        y = abs(cosas[cnt]-cosas[cnt-1])\n",
    "        # adapted the data generator to yield both sin and cos\n",
    "        yield t, y\n",
    "\n",
    "data_gen.t = 0\n",
    "\n",
    "%matplotlib nbagg\n",
    "\n",
    "# create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "\n",
    "# intialize a line object on the second axes for plotting\n",
    "line, = ax2.plot([], [], lw=2, color='r')\n",
    "\n",
    "ax2.set_ylim(0, 2)\n",
    "ax2.set_xlim(0, 5)\n",
    "ax2.grid()\n",
    "\n",
    "# initialize the data arrays \n",
    "xdata, ydata = [], []\n",
    "def run(data):\n",
    "    # update the data plot\n",
    "    t, y = data\n",
    "    xdata.append(t) # time = x axis\n",
    "    ydata.append(y) # y axis\n",
    "\n",
    "    # Plot image on top row\n",
    "    ax1.imshow(ic[len(xdata)])\n",
    "          \n",
    "    # Plot sin in bottom row\n",
    "    xmin, xmax = ax2.get_xlim()\n",
    "    if t >= xmax:\n",
    "        ax2.set_xlim(xmin, 2*xmax)\n",
    "        ax2.figure.canvas.draw()\n",
    "            \n",
    "    # update the data of both line objects\n",
    "    line.set_data(xdata, ydata)\n",
    "\n",
    "    return line\n",
    "\n",
    "ani = animation.FuncAnimation(fig, run, data_gen, blit=True, interval=10, repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We crete a function that displays 2 images with their respective titles\n",
    "def print_1x2(imatge,imatge_despres):\n",
    "    fig, axarr = plt.subplots(1,2)\n",
    "    fig.set_size_inches(25,10)\n",
    "    \n",
    "    #imatge\n",
    "    axarr[0].imshow(imatge,cmap='gray')\n",
    "    axarr[0].set_title('Inici de seqüència')\n",
    "    axarr[0].xaxis.set_visible(False)\n",
    "    axarr[0].yaxis.set_visible(False)\n",
    "    \n",
    "    #imatge després\n",
    "    axarr[1].imshow(imatge_despres, cmap='gray')\n",
    "    axarr[1].set_title('Final de seqüència')\n",
    "    axarr[1].xaxis.set_visible(False)\n",
    "    axarr[1].yaxis.set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "hard_jump = []\n",
    "thr = 0.71\n",
    "\n",
    "last_idx = 0\n",
    "\n",
    "# We check where the sequences end defining a threshold 'thr' defined by our graph\n",
    "for i in range(1,len(cosas)):\n",
    "    if(abs(cosas[i-1]-cosas[i]) >= thr):\n",
    "        print_1x2(ic[last_idx],ic[i-1])\n",
    "        hard_jump.append((last_idx,i))\n",
    "        last_idx = i+1\n",
    "\n",
    "# We must check if there is a sequence between the last_idx found and the last image\n",
    "\n",
    "if(last_idx != len(ic)):    \n",
    "    print_1x2(ic[last_idx], ic[-1])\n",
    "    hard_jump.append((last_idx, len(ic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Background substraction\n",
    "\n",
    "Apply the background substraction algorithm (check theory material).\n",
    "\n",
    "Visualize, for each shot of the video:\n",
    "    1) images belonging to the shot\n",
    "    2) the background image, and\n",
    "    3) the foreground.\n",
    "    \n",
    "**Hint**: You can construct a mask obtained from the original image and the background in order to know which parts of the image form part from the foreground and recover from the original image just the foreground regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import img_as_float\n",
    "\n",
    "def print_1x1(imatge,title):\n",
    "    fig, axarr = plt.subplots(1,1)\n",
    "    fig.set_size_inches(10,10)\n",
    "    \n",
    "    #image\n",
    "    axarr.imshow(imatge,cmap='gray')\n",
    "    axarr.set_title(title)\n",
    "    axarr.xaxis.set_visible(False)\n",
    "    axarr.yaxis.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def find_background(start,end):\n",
    "    \n",
    "    # We define an image with the same shape as the original ones just to fill it later\n",
    "    background_image = np.zeros([ic[0].shape[0],ic[0].shape[1], ic[0].shape[2]], np.uint8)\n",
    "    \n",
    "    # We substract the sequence we want to extract the background\n",
    "    sequence = ic[start:end]\n",
    "    \n",
    "    # We need\n",
    "    red_channel_arr = []\n",
    "    green_channel_arr = []\n",
    "    blue_channel_arr = []\n",
    "    \n",
    "    for img in sequence:\n",
    "        red_channel_arr.append(img_as_float(img[:,:,0]))\n",
    "        green_channel_arr.append(img_as_float(img[:,:,1]))\n",
    "        blue_channel_arr.append(img_as_float(img[:,:,2]))\n",
    "        \n",
    "    #we calculate the median for every channel, using every image in shot_images\n",
    "    red_channel_median = np.median(red_channel_arr, axis = 0)       \n",
    "    green_channel_median = np.median(green_channel_arr, axis = 0)       \n",
    "    blue_channel_median = np.median(blue_channel_arr, axis = 0)       \n",
    "    \n",
    "    for i in range(sequence[0].shape[0]):\n",
    "        for j in range(sequence[0].shape[1]):\n",
    "            background_image[i,j] = [red_channel_median[i,j]*255,green_channel_median[i,j]*255,blue_channel_median[i,j]*255]\n",
    "\n",
    "    return background_image\n",
    "\n",
    "idx = 1\n",
    "for pair in hard_jump:\n",
    "    print_1x1(find_background(pair[0],pair[1]), \"Background sequence \"+str(idx))\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment your implementation including details. What happens if the shots are not correctly extracted? What happens if you find too many shots in the video? What do the static background images represent? In which situations does the algorithm work and in which it does not? What happens if you substract the background image from the original one?\n",
    "\n",
    "Do you see any additional application for this algorithm?\n",
    "\n",
    "**[OPTIONAL]**\n",
    "Apply the algorithm to some other static video that you found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation is commented inside itself.\n",
    "\n",
    "If the shots are not correctly extracted, the background image will be computed along the out-shot images which will end up being worse than the correct one (depending on how many out-shot images from all of them we take).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_mean\n",
    "from skimage import img_as_float\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def print_1x1(imatge,title):\n",
    "    fig, axarr = plt.subplots(1,1)\n",
    "    fig.set_size_inches(10,10)\n",
    "    \n",
    "    #imatge\n",
    "    axarr.imshow(imatge,cmap='gray')\n",
    "    axarr.set_title(title)\n",
    "    axarr.xaxis.set_visible(False)\n",
    "    axarr.yaxis.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "extraction = ic[0] - threshold_mean(find_background(hard_jump[0][0],hard_jump[0][1]))\n",
    "print_1x1((extraction*255).astype('uint8'), \"Background extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.3 Clustering methods on the RGB-XY space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Read any image from the folder 'images' and segment it using Felzenszwalbs's method. Test different parameters in order to obtain a good image segmentation. How does each parameter behave? Which are the optimal values? Comment what algorithm is the method based in up to 3 lines most.\n",
    "\n",
    "**Hint**: \n",
    "- Different image segmentation commands can be found in skimage.segmentation.\n",
    "- Use the function segmentation.mark_boundaries for seeing the boundaries of the segments.\n",
    "- Use the inline pluggin to visualize images (%matplotlib inline)\n",
    "- Add title to the figures to explain what is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Segment the previous image using SLIC algorithm. Test different parameters in order to obtain a good image segmentation. How does each parameter behave? Upt o your opinion, which are the optimal values? Comment what algorithm is the method based in up to 3 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Plot the original image and the results of both algorithms in a 1x3 subplot. Calculate also the number of segments obtained on the image by each of the algorithms. Comment the differences between each method as well as their advantages and disadvantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
